# 测试  

### 底层测试  

底层测试类包含测量深度学习神经网络里的基本操作性能的测试。这一类主要针对GPU硬件并包含如下测试。 

1. GEMM  
  矩阵乘法是很多科学，工程，和机器学习应用里面的一项基本操作。优化矩阵乘法一直是一个需求。从这个角度看，矩阵乘法的性能是AI加速器能力的表征。这个测试包含一系列不同参数的矩阵乘法，卷积，和内存运算。 

### 单层测试 

神经网络由一个或者多个层组成，每一层包括一些常用的操作。为了更好的调查神经网络的性能，评估单层的性能不可避免。层测试使用一些重要的操作产生不同的层去测试单独的层在AI加速器上的性能。

### 完整测试 

完整测试包含CNN和RNN模型。这一类测试的目的是测量完整模型的性能，重点在于测试推导的性能。模型的重量参数通过训练这些网络几百个来回得到，训练开始时这些参数被初始化为随机数（这对性能测试足够了）。这些测试有两个软件框架：tensorflow和caffe。Caffe模型和重量参数被送到TensorRT上优化，结果是基于TensorRT优化之后的计算图。Tensorflow模型是在tensorflow框架里编写和测试的。CNN模型先被训练几百个来回以产生初始的检查点文件，这些检查点文件再被用到推导中。我们的模型数据库始终追踪学术界和工业界最新的算法和模型发展。满足筛选条件的新模型会被加入我们的测试中。  

宏测试收集了一些学术届和工业界常用的模型，包括CNN模型和ILSVRC冠军模型。除此以外，还包括一些基于RNN的应用。这些模型被完整的跑下来以评估它们的性能。这些模型包含一下几类。  
1. 图像分类  
CNN模型包含以下模型，分别用tensorRT优化的caffe和tensorflow实现的。  
    * googlenet   
    * vgg16  
    * resnet50  
    * resnet152  
    * densenet  
2. 物体识别  
    2.1 Mask RCNN  
    作为ILSCVRC的一项挑战，出现了很多重要的和流行的物体探测的算法。我们在我们的测试中收集了Mask RCNN。在Mask RCNN框架中，resnet101是主要支柱。推导测试了28个图像。每一个图像被复制n次以增大batch size。所以总共探测的图像数量是28n。我们从这里收集Mask RCNN的源代码  
    https://github.com/matterport/Mask_RCNN  
    2.2 SSD  
    Single Shot MultiBox Detector (SSD)在2016年被提出并且被许多计算机图形研究者和工程师应用。对物体识别领域有重大影响。我们从这里收集SSD的源代码  
    https://github.com/balancap/SSD-Tensorflow  
3. NMT  
神经机器翻译（NMT）是一个基于序列到序列到模型。这个模型在2014年被提出并且改进了一系列的任务，例如，机器翻译，语音识别，和文本总结。很多研究者和算法工程师会直接使用或者修改这个模型。我们从这里收集到NMT的代码 
https://github.com/tensorflow/nmt  
4. DeepSpeech  
DeepSpeech是一个由百度在2014年提出的语音识别框架。这是由Firefox开源项目在tensorflow中重新实现的。 Deepspeech核心架构基于组织良好的RNN网络和一些数据合成技术，允许用户有效地训练系统。 我们从这里收集到DeepSpeech的代码  
https://github.com/mozilla/DeepSpeech  
5. Deep Interest Network（来自阿里妈妈）
阿里妈妈属于阿里巴巴集团，是阿里巴巴集团核心业务数据的大数据领先营销平台。 Deep Interest Network（DIN）由阿里妈妈工程师开发，现已成功部署在阿里巴巴的在线展示广告系统中，为主要流量提供服务。 该框架解决了点击率（CTR）预测的问题，这是工业应用中的重要任务，例如在线广告。 CTR预测模型的性能对最终收入有直接影响，并在广告系统中起关键作用。 该模型在阿里巴巴集团中发挥着重要作用。
模型由“深度兴趣网络点击率预测”的作者提供。 感谢Guorui Zhou，Peng Sun，Zelin Hu等人的贡献。  
https://github.com/zhougr1993/DeepInterestNetwork  

### 合成测试 (StatsNet)  
深度学习（DL）架构，例如卷积神经网络（CNN），涉及大量计算并且需要硬件（例如CPU，GPU和AI加速器）来提供巨大的计算能力。 由于市场上普遍存在多种AI硬件，因此通常很难确定哪种硬件最适合使用。 因此，有效地对AI硬件进行基准测试变得非常重要，并且对选择和优化AI硬件有很大帮助。  
不幸的是，目前的AI基准测试总是遇到传统基准测试的一些缺点。 首先，它们无法适应DL算法的新兴变化，并且一旦被选中就固定不变了。 其次，它们包含数十到数百个应用程序，并且需要很长时间才能完成运行。 第三，它们主要选自开源，受版权限制，不能代表专有应用。  
我们提出了一个合成测试模型来解决AI基准测试的上述缺点。 合成方法不是预先选择一组开源测试并运行所有这些测试，而是通过分析各种应用程序的负载特征，仅生成一个或几个测试，这些测试最能代表这些应用程序。 因此，它可以通过重新分析新应用程序和更新自身来适应新DL算法的新变化，大大减少测试数目和运行时间，并能很好的代表DL应用程序。合成测试被用来测试硬件性能。

### 建议  
我们仍在努力开发我们的基准测试套件。 我们欢迎任何人的任何建议，贡献和改进。 同时也欢迎您的参与。您可以在Github上提交问题或通过 aimatrix@list.alibaba-inc.com 与我们联系。
