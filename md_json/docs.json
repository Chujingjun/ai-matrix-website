{
  "zh-cn": [
    {
      "filename": "demo1.md",
      "__html": "<h1>脚注的使用</h1>\n<p>这是一段示例文字，展示脚注的使用。\n这是脚注1 <sup class=\"footnote-ref\"><a href=\"#fn1\" id=\"fnref1\">[1]</a></sup>。点击脚注滚动至对应脚注处。</p>\n<p>下面是一大段文字，填充开始。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。\n这是填充文字。</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>这是脚注的说明 <a href=\"#fnref1\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n"
    },
    {
      "filename": "demo2.md",
      "__html": "<h1>文档之间跳转、图片引用的示例</h1>\n<p>文档之间的跳转链接按照文件目录之间的相对关系配置即可，推荐在同一语言目录下的不同文件夹间跳转，以缩短配置路径。\n点击跳转： <a href=\"./demo1.md\">demo1.md</a>。</p>\n<p>图片的引用，支持绝对引用和相对引用，如果是相对引用，同文档之间的相互引用一样，是按照文件之间的相对路径进行处理的。比如\n<img src=\"./img/brhtqqzh.jpeg\" alt=\"\"></p>\n"
    },
    {
      "filename": "dir/demo3.md",
      "__html": "<h1>跨目录文档之间跳转、图片引用的示例</h1>\n<p>这是一段文字，将要跳转到demo1。\n文档之间的跳转链接按照文件目录之间的相对关系配置即可，推荐在同一语言目录下的不同文件夹间跳转，以缩短配置路径。\n点击跳转： <a href=\"../demo1.md\">demo1.md</a>。</p>\n<p>图片的引用，支持绝对引用和相对引用，如果是相对引用，同文档之间的相互引用一样，是按照文件之间的相对路径进行处理的。比如\n<img src=\"../img/brhtqqzh.jpeg\" alt=\"\"></p>\n"
    },
    {
      "filename": "results.md",
      "__html": "<p>Coming soon...</p>\n"
    }
  ],
  "en-us": [
    {
      "filename": "contents.md",
      "__html": "<h1>Benchmarks</h1>\n<h3>Micro Benchmarks</h3>\n<p>The micro benchmark category consists of tests that measure the performance of the basic operations involved in training deep learning neural networks. This category mainly targets the GPU hardware platform and consists of the following tests.</p>\n<ol>\n<li>GEMM<br>\nMatrix-matrix multiplication (GEMM) is a fundamental operation in many scientific, engineering, and machine learning applications. There is a continuing demand to optimize this operation. From this point of view, the performance of GEMM is fundamental capability of an AI accelerator. This test consists of a variaty of differently parameterized GEMM operations, convolution, and memory operations.</li>\n</ol>\n<h3>Layer-based Benchmarks</h3>\n<p>The neural networks are consisted of one or more different layers and each layer involves some commonly used operations. To better investigate the perfomrance of a neural network, it is inevitable to perform the evaluation on single layer performance. The layer-based benchmarks create layers using these important operations and aim at testing the performance of isolated layers on AI accelerators.</p>\n<h3>Macro Benchmarks</h3>\n<p>The macro benchmarks include the CNN and RNN models. The purpose of this benchmarks to test the performance of complete models with focus on inference. The models weights are obtained by trained on a few hundreds iterations with initial random numbers (it is enough for performance testing purpose). They will be tested in two frameworks: caffe and tensorflow. Caffe models and weights are input to TensorRT and the results are based on TensorRT optimized graph. Tensorflow models are coded and tested in Tensorflow framework. The CNN models need to train a few hundreds iterations get obtain the initial checkpoint files. Later, these files are used in inference test phase.<br>\nOur model database tracks the academia and industry innovative development of new algorithm and models all the time. New models could be added if they are satisfied with our selection standards.</p>\n<p>The macro benchmarks collect a couple of commonly used models in both academia and industry, including CNN models of ILSVRC champions. Besides, it also include some RNN based application in NLP. This benchmarks are evaluated for their performance of running the complete models to get sense of the performance data for some major applications categories.</p>\n<ol>\n<li>\n<p>Image classification<br>\nThe CNN models consist of the following below. The caffe with tensorRT and tensorflow implementations are included.</p>\n<ul>\n<li>googleneti</li>\n<li>vgg16</li>\n<li>resnet50</li>\n<li>resnet152</li>\n<li>densenet</li>\n</ul>\n</li>\n<li>\n<p>Object detection<br>\n2.1 Mask RCNN<br>\nAs one of the challenge in ILSVRC (ImageNet Large Scale Visual Recognition Challenge), object detection emerged many important and prevailing algorithm also. We collected the Mask RCNN merged in 2017 in our benchmarks. In the Mask RCNN framework, resnet101 is used as backbone in this test framework. 28 images are tested in the inference situation. Each image is duplicated to make larger batch size = n. So total image detected in this test is 28*n.\nWe collect the code from below.<br>\n<a href=\"https://github.com/matterport/Mask_RCNN\">https://github.com/matterport/Mask_RCNN</a></p>\n<p>2.2 SSD<br>\nSingle Shot MultiBox Detector (SSD) is  proposed in 2016 and is being used and customized by many compute vision researchers and engineers. It has quite a lot impact to the object detection area.\nWe collect the code from below which is re-implementation of original caffe implementation.<br>\n<a href=\"https://github.com/balancap/SSD-Tensorflow\">https://github.com/balancap/SSD-Tensorflow</a></p>\n</li>\n<li>\n<p>NMT<br>\nNeural machine translation (NMT) is based sequence-to-sequence (seq2seq) models.  The seq2seq models are proposed in 2014 and have improved a variety of tasks such as machine translation, speech recognition, and text summarization. Many researcher and algorithm engineer would directly use or customize it based on this model.<br>\nWe collect the code from below<br>\n<a href=\"https://github.com/tensorflow/nmt\">https://github.com/tensorflow/nmt</a></p>\n</li>\n<li>\n<p>DeepSpeech<br>\nDeepspeech is speech recognition framework proposed by Baidu in 2014. This is re-implementation of it in tensorflow by Firefox open source project. Deepspeech core architecture is based on well organized RNN network with some data systhesis techniques that allow users to train the system efficiently.\nWe collect the code from below<br>\n<a href=\"https://github.com/mozilla/DeepSpeech\">https://github.com/mozilla/DeepSpeech</a></p>\n</li>\n<li>\n<p>Deep Interest Network (from Alimama)<br>\nAlimama belongs to Alibaba Group, is a leading marketing platform for Big Data with Alibaba Group's core business data. Deep Interest Network (DIN) is developed by Alimama engineer and now has been successfully deployed in the online display advertising system in Alibaba, serving the main traffic. The framework addresses the problem of click-through rate (CTR) prediction which is an essential task in industrial applications, such as online advertising. The performance of CTR prediction model has a direct impact on the final revenue and plays a key role in the advertising system. This model plays an important role in Alibaba Group.<br>\nModel are contributed by the authors of &quot;Deep Interest Network for Click-Through Rate Prediction&quot;. Thanks for the contribution from Guorui Zhou, Peng Sun, Zelin Hu, etc..<br>\n<a href=\"https://github.com/zhougr1993/DeepInterestNetwork\">https://github.com/zhougr1993/DeepInterestNetwork</a></p>\n</li>\n</ol>\n<h3>Synthetic Benchmarks</h3>\n<p>Deep learning (DL) architecture, such as convolutional neural networks (CNN), involves heavy computation and require hardware, such as CPU, GPU, and AI accelerators, to provide the massive computing power. With the many varieties of AI hardware prevailing on the market, it is often hard to decide which one is the best to use. Thus, benchmarking AI hardware effectively becomes important and is of great help to select and optimize AI hardware.</p>\n<p>Unfortunately, the current AI benchmarks always suffer some drawbacks of traditional benchmarks. First, they cannot adapt to the emerging changes of DL algorithms and are fixed once selected. Second, they contain tens to hundreds of applications and take very long time to finish running. Third, they are mainly selected from open sources, which are restricted by copyright and are not representable to proprietary applications.</p>\n<p>We propose a synthetic benchmarks framework is firstly proposed to address the above drawbacks of AI benchmarks. Instead of pre-selecting a set of open-sourced benchmarks and running all of them, the synthetic approach generates only a one or few benchmarks that best represent a broad range of applications using profiled workload characteristics data of these applications. Thus, it can adapt to emerging changes of new DL algorithms by re-profiling new applications and updating itself, greatly reduce benchmark count and running time, and strongly represent DL applications of interests. The generated benchmarks serve as a performance benchmarks matching the statistical workload characteristics of a combination of applications of interests.</p>\n<h1>Suggestions</h1>\n<p>We are still keep working hard to developing our benchmark suites. We are welcome to any suggestions, contributions and improvements from anyone. Please do not hesitate to contact us if you want to involve. Thanks.\nYou could submit questions on Github or contact us through <a href=\"mailto:w.wei@alibaba-inc.com\">w.wei@alibaba-inc.com</a></p>\n"
    },
    {
      "filename": "demo2.md",
      "__html": "<h1>demo for reference of md or image for relative path</h1>\n<p>if you want to reference to another md, the path can be written in the format of relative path under the circumstance of file system.\nclick here： <a href=\"./demo1.md\">demo1.md</a>。</p>\n<p>the same is to image.\n<img src=\"./img/brhtqqzh.jpeg\" alt=\"\"></p>\n"
    },
    {
      "filename": "dir/demo3.md",
      "__html": "<h1>demo for reference of md or image for relative path, across directory</h1>\n<p>if you want to reference to another md, the path can be written in the format of relative path under the circumstance of file system.\nclick here： <a href=\"../demo1.md\">demo1.md</a>。</p>\n<p>the same is to image.\n<img src=\"../img/brhtqqzh.jpeg\" alt=\"\"></p>\n"
    },
    {
      "filename": "goals.md",
      "__html": "<p>Goal\nAI Matrix is a benchmark suite for testing AI software frameworks and hardware platforms. It aims at providing users a means of measuring the performance of different AI sofware and hardware and comparing their pros and cons. It also helps users gain insights into the factors that affect AI hardware performance and improve hardware design.</p>\n<p><img src=\"./structure.jpg\" alt=\"img\"><br>\nThe AI Matrix suite consists of four categories of tests: micro benchmarks, layer-based benchmarks, macro benchmarks, and synthetic benchmarks. The testing granularity of test sub-category is increasing. Micro benchmarks focus on basic hardware level GEMM compuation which is also important to AI computation; layer-based benchmarks focus on evaluating the basic element of neural network; macro benchmarks evaluate the complete models from different application areas. Majority of the application are tested on tensorflow while CNN tests are also evaluated in caffe. Tensorflow is one of the most important framework in AI application area and it widely used in Alibaba also. Caffe is one of pioneer in the AI framework and there are still a lot of legacy models wrtitten in Caffe. Due to our limited resources, we only collect test cases from these two frameworks but in future, we will extend our collection in other frameworks.</p>\n"
    },
    {
      "filename": "metrics.md",
      "__html": "<h1>Metrics</h1>\n<p>There are a lot of factors affect the AI applications' final performance on hard accelerators. However, the fundamental and intuitive metric would be the running time (<strong>wall clock time</strong>). In our test suites, we use wall clock  as the basic metrics. In the current market of inference and training, NVIDIA products play an important role in it. Although Google TPU has been on public cloud but accessibility is still limited. Here to give a score to every test. We propose to use the flagship product of Nvidia as baseline. We use P4 as inference and V100 as training baseline. In future, we consider some normalization metrics to adjust the value. For ex, energy consumption. But as it is till not very reliable, we are still waiting some better condition to normalize these metrics.</p>\n<p>In the coming revised versions, we propose to consider the following metrics as normalization metrics.</p>\n<ul>\n<li>Energy consumption of running a benchmark</li>\n<li>hardware utilization</li>\n</ul>\n"
    },
    {
      "filename": "results.md",
      "__html": "<p>Coming soon...</p>\n"
    }
  ]
}